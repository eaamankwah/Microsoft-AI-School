{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering\n",
    "======\n",
    "\n",
    "When a data set doesnâ€™t have labels we can use unsupervised learning to find some kind of structure in the data - allowing us to discover patterns or groupings.\n",
    "\n",
    "Cluster analysis is a method of finding groupings, known as clusters, in datasets. As the data sets are unlabelled, cluster analysis tries to group similar examples using the examples features.\n",
    "\n",
    "K-means clustering lives true to its name - it separates examples into k number of clusters (so if k is 5, it will divide the examples into 5 clusters) and it partitions the examples by the average (mean) of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1\n",
    "-----\n",
    "\n",
    "In this exercise we will look at using k-means clustering to categorise a few different datasets.\n",
    "\n",
    "Let's start by first creating three clusters.\n",
    "\n",
    "#### Run the code below to set up the graphing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets up the graphs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as graph\n",
    "%matplotlib inline\n",
    "graph.rcParams['figure.figsize'] = (15,5)\n",
    "graph.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "graph.rcParams[\"font.size\"] = '12'\n",
    "graph.rcParams['image.cmap'] = 'rainbow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below replace:\n",
    "#### 1. `<addClusterData>` with `cluster_data`\n",
    "#### 2. `<addOutput>` with `output`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some data!\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "###\n",
    "# REPLACE <addClusterData> WITH cluster_data AND <addOutput> WITH output\n",
    "###\n",
    "<addClusterData>, <addOutput> = datasets.make_classification(n_samples = 500, n_features = 2, n_informative = 2, n_redundant = 0, n_repeated = 0,\n",
    "                                                    n_classes = 3, n_clusters_per_class = 1, class_sep = 1.25, random_state = 6)\n",
    "###\n",
    "\n",
    "# Let's visualise it\n",
    "graph.scatter(cluster_data.T[0], cluster_data.T[1])\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how k-means performs on a dataset like this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below replace:\n",
    "#### 1. `<addKMeans>` with `KMeans`\n",
    "#### 2. `<addFit>` with `fit`\n",
    "#### 3. `<addClusterCenters>` with `k_means.cluster_centers_`\n",
    "#### 4. `<addLabels>` with `k_means.labels_`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "###\n",
    "# REPLACE <addKMeans> WITH KMeans\n",
    "###\n",
    "k_means = KMeans(n_clusters=3)\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE <addFit> WITH fit\n",
    "###\n",
    "k_means.fit(cluster_data)\n",
    "###\n",
    "\n",
    "# Let's visualise it\n",
    "###\n",
    "# REPLACE <addClusterCenters> BELOW WITH k_means.cluster_centers_\n",
    "###\n",
    "for mean in <addClusterCenters>:\n",
    "    graph.plot(mean[0], mean[1], 'ko', marker = '+', markersize = 20)\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE <addLabels> BELOW WITH k_means.labels_\n",
    "###\n",
    "graph.scatter(cluster_data.T[0], cluster_data.T[1], c = <addLabels>)\n",
    "###\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs rather well, by the looks of it! But we already knew that it had three clusters, sometimes it might not be so clear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Let's generate another dataset in which it may be a little less obvious how many classes it contains.\n",
    "\n",
    "#### Replace `<addMakeClassification>` with `datasets.make_classification` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# REPLACE <addMakeClassification> BELOW WITH datasets.make_classification\n",
    "###\n",
    "cluster_data, output = <addMakeClassification>(n_samples = 500, n_features = 2, n_informative = 2, n_redundant = 0, n_repeated = 0, \n",
    "                                            n_classes = 4, n_clusters_per_class = 1, class_sep = 1.25, random_state = 6)\n",
    "###\n",
    "\n",
    "graph.scatter(cluster_data.T[0], cluster_data.T[1])\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In instances where we do not know how many classes to expect, it is handy to run k-means multiple times and compare how the data looks when divided up into a differing number of classes. Let's try that now.\n",
    "\n",
    "#### Replace `<addNHere>` with `n` and run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# REPLACE <addNHere> BELOW WITH n\n",
    "###\n",
    "for <addNHere> in range(2,6):\n",
    "    k_means = KMeans(n_clusters = <addNHere>).fit(cluster_data)\n",
    "###\n",
    "\n",
    "    for mean in k_means.cluster_centers_:\n",
    "        graph.plot(mean[0], mean[1], 'ko', marker = '+', markersize = 20)\n",
    "    graph.scatter(cluster_data.T[0], cluster_data.T[1], c = k_means.labels_)\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one do you think best splits the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3\n",
    "========\n",
    "\n",
    "K-means clustering performs well enough on clustered data like that, but let's try it out on a dataset that is not so linear.\n",
    "\n",
    "#### Replace `<addMakeCircles>` with `make_circles` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# REPLACE <addMakeCircles> BELOW WITH make_circles\n",
    "###\n",
    "ring_data, target = datasets.<addMakeCircles>(n_samples = 500, factor = .5, noise = 0.05, random_state = 6)\n",
    "###\n",
    "\n",
    "graph.scatter(ring_data.T[0], ring_data.T[1], c = target)\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly distinguish two \"clusters\", that is, the two rings of datapoints.\n",
    "\n",
    "Let's see how k-means handles a dataset like this.\n",
    "\n",
    "#### Replace `<addRingData>` with `ring_data` and run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# REPLACE <addRingData> BELOW WITH ring_data\n",
    "###\n",
    "k_means = KMeans(n_clusters = 2).fit(<addRingData>)\n",
    "###\n",
    "\n",
    "for mean in k_means.cluster_centers_:\n",
    "    graph.plot(mean[0], mean[1], 'ko', marker = '+', markersize = 20)\n",
    "graph.scatter(ring_data.T[0], ring_data.T[1], c = k_means.labels_)\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clearly has difficulty solving this.\n",
    "\n",
    "As we are using it, there is no way for k-means to place two means to label this data set correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4\n",
    "------\n",
    "\n",
    "But, we can try another way. We can use another feature - distance away from the centre.\n",
    "\n",
    "Let's see if k-means is able to classify the two data clusters with this new feature.\n",
    "\n",
    "#### Replace `<addSqrt>` with `np.sqrt` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_from_center = []\n",
    "for sample in ring_data:\n",
    "###\n",
    "# REPLACE <addSqrt> BELOW WITH np.sqrt\n",
    "###\n",
    "    z = 4 * <addSqrt>(sample[0]**2 + sample[1]**2)\n",
    "###\n",
    "    distance_from_center.append(z)\n",
    "# Make it a three-dimensional dataset\n",
    "ring_data = np.concatenate((ring_data, np.array(distance_from_center).reshape(-1, 1)), axis = 1)\n",
    "\n",
    "graph.scatter(ring_data.T[0], ring_data.T[1], c = ring_data.T[2])\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it will work, so let's plot all three features.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addProjection>` with `projection='3d'`\n",
    "#### 2. `<addRingDataT>` with `ring_data.T[2]`\n",
    "#### and then __run the code__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = graph.figure()\n",
    "###\n",
    "# REPLACE <addProjection> BELOW WITH projection='3d'\n",
    "###\n",
    "ax = fig.add_subplot(111, <addProjection>)\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE <addRingDataT> BELOW WITH ring_data.T[2]\n",
    "###\n",
    "ax.scatter(ring_data.T[0], ring_data.T[1], <addRingDataT>, c = target)\n",
    "###\n",
    "\n",
    "ax.view_init(30, 45)\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how k-means deals with the data now that it has 3 features!\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addRingData>` with `ring_data`\n",
    "#### 2. `<addLabels>` with `k_means.labels_`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# REPLACE <addRingData> BELOW WITH ring_data\n",
    "###\n",
    "k_means = KMeans(n_clusters = 2, random_state = 0).fit(<addRingData>)\n",
    "###\n",
    "\n",
    "fig = graph.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for mean in k_means.cluster_centers_:\n",
    "    ax.scatter(mean[0], mean[1], mean[2], c='black', marker='+', s=50) # plot the cluster centres\n",
    "    \n",
    "###\n",
    "# REPLACE <addLabels> BELOW WITH k_means.labels_\n",
    "###\n",
    "ax.scatter(ring_data.T[0], ring_data.T[1], ring_data.T[2], c = <addLabels>)\n",
    "###\n",
    "\n",
    "# We can plot a hyperplane that separates the two rings\n",
    "hp_X, hp_Y = np.array(np.meshgrid(np.linspace(-1, 1, 11), np.linspace(-1, 1, 11)))\n",
    "hp_Z = np.full(hp_X.shape, np.abs(k_means.cluster_centers_[0][2] - k_means.cluster_centers_[1][2] / 2))\n",
    "ax.plot_wireframe(hp_X, hp_Y, hp_Z, rstride = 1, cstride = 1, \n",
    "                  color = 'k', linewidth = 1, linestyle = 'solid', alpha = 0.5)\n",
    "\n",
    "ax.view_init(20, 45)\n",
    "ax.set_zlabel('new axis')\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the `+` that indicates the center of the clusters. Looks good!\n",
    "\n",
    "Step 5\n",
    "------\n",
    "\n",
    "Some data we cannot manipulate like that. Let's have a look at a different type of data distribution.\n",
    "\n",
    "#### Replace `<addMakeMoons>` with `datasets.make_moons` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# REPLACE <addMakeMoons> BELOW WITH datasets.make_moons\n",
    "###\n",
    "crescent_data, output = <addMakeMoons>(n_samples = 500, noise = .05)\n",
    "###\n",
    "\n",
    "graph.scatter(crescent_data.T[0], crescent_data.T[1], c = target)\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try fitting it.\n",
    "\n",
    "#### Replace `<addCrescentData>` with `crescent_data` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we run KMeans on crescent_data using n_clusters = 2\n",
    "###\n",
    "# REPLACE <addCrescentData> WITH crescent_data\n",
    "###\n",
    "k_means = KMeans(n_clusters = 2).fit(<addCrescentData>)\n",
    "###\n",
    "\n",
    "for mean in k_means.cluster_centers_:\n",
    "    graph.plot(mean[0], mean[1], 'ko', marker = '+', markersize = 20)\n",
    "graph.scatter(crescent_data.T[0], crescent_data.T[1], c = k_means.labels_)\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a similar issue as with the circle data.\n",
    "\n",
    "But k-means is just one method for clustering, other methods don't have quite the same restrictions as k-means.\n",
    "\n",
    "Step 6\n",
    "------\n",
    "\n",
    "Spectral clustering is a clustering method that aims to cluster data that is in some way connected - but not necessarily distributed.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addSpectralClustering>` with `SpectralClustering`\n",
    "#### 2. `<addCrescentData>` with `crescent_data`\n",
    "#### 3. `<addLabels>` with `labels_`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "###\n",
    "# REPLACE <addSpectralClustering> BELOW WITH SpectralClustering\n",
    "###\n",
    "spectral = cluster.<addSpectralClustering>(n_clusters = 2, eigen_solver = 'arpack', affinity = 'nearest_neighbors')\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE <addCrescentData> BELOW WITH crescent_data\n",
    "###\n",
    "labels_ = spectral.fit_predict(<addCrescentData>)\n",
    "###\n",
    "\n",
    "### \n",
    "# REPLACE <addLabels> BELOW WITH labels_\n",
    "###\n",
    "graph.scatter(crescent_data.T[0], crescent_data.T[1], c = <addLabels>)\n",
    "###\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below replace:\n",
    "#### 1. `<addSpectralClustering>` with `SpectralClustering`\n",
    "#### 2. `<addRingData>` with `ring_data`\n",
    "#### 3. `<addLabels>` with `labels_`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use spectral clustering on the ring_data\n",
    "\n",
    "###\n",
    "# REPLACE <addSpectralClustering> BELOW WITH SpectralClustering\n",
    "###\n",
    "spectral = cluster.<addSpectralClustering>(n_clusters = 2, eigen_solver = 'arpack', affinity = 'nearest_neighbors')\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE <addRingData> BELOW WITH ring_data\n",
    "###\n",
    "labels_ = spectral.fit_predict(<addRingData>)\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE <addLabels> BELOW WITH labels_\n",
    "###\n",
    "graph.scatter(ring_data.T[0], ring_data.T[1], c = <addLabels>)\n",
    "###\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it classify the data in the correct clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have learnt two important clustering methods, k-means and spectral clustering, and used them on a variety of datasets where one might be more appropriate to use than the other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
